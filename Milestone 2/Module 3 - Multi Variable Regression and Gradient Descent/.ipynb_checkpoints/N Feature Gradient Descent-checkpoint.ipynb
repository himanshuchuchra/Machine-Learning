{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c77b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ea8be0",
   "metadata": {},
   "source": [
    "## Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee6d99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'boston_house_prices.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_boston()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fcfb5a",
   "metadata": {},
   "source": [
    "## Spliting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "917af42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 3.9690e+02, 4.9800e+00,\n",
       "         1.0000e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 3.9690e+02, 9.1400e+00,\n",
       "         1.0000e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 3.9283e+02, 4.0300e+00,\n",
       "         1.0000e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 3.9690e+02, 5.6400e+00,\n",
       "         1.0000e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 3.9345e+02, 6.4800e+00,\n",
       "         1.0000e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 3.9690e+02, 7.8800e+00,\n",
       "         1.0000e+00]]),\n",
       " array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.data\n",
    "Y = data.target\n",
    "X = np.append(X, np.ones(len(X), dtype='int').reshape(-1, 1), axis=1)\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803b7424",
   "metadata": {},
   "source": [
    "## Gradient Decent Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a5be0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent():\n",
    "    learning_rate = 0.000001\n",
    "    iterations = 500\n",
    "    m = find_M(X,Y,learning_rate,iterations)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f605011d",
   "metadata": {},
   "source": [
    "## find_M Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64772315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_M(X,Y,learning_rate,iterations):\n",
    "    m = np.array([0 for i in range(len(X[0]))])\n",
    "    for i in range(iterations):\n",
    "        m = step_gradient(X,Y,learning_rate,m)\n",
    "        print(\"Cost:\",cost(X,Y,m))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3437fa3c",
   "metadata": {},
   "source": [
    "## step_gradient Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3ba430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(X,Y, learning_rate, m):\n",
    "    m_slope = np.array([0 for i in range(len(X[0]))])\n",
    "    N = len(X)\n",
    "    for i in range(N):\n",
    "        x = X[i]\n",
    "        y = Y[i]\n",
    "        for j in range(len(m_slope)):\n",
    "            m_slope[j] += (-2/N)*(y - (m*x).sum())*(x[j])\n",
    "    new_m = m - learning_rate * m_slope\n",
    "    return new_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc8d286",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a43bb91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(X,Y,m):\n",
    "    result = 0\n",
    "    N = len(X)\n",
    "    for i in range(N):\n",
    "        result += (2/N)*(Y[i]-sum(m*X[i]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1cd545f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 19.330945601757023\n",
      "Cost: 9.637146448555411\n",
      "Cost: 5.953660858003798\n",
      "Cost: 4.5057366314806435\n",
      "Cost: 3.8873536780750935\n",
      "Cost: 3.603202441925844\n",
      "Cost: 3.4420604912244936\n",
      "Cost: 3.3427757441875063\n",
      "Cost: 3.2520696230052097\n",
      "Cost: 3.176973447107825\n",
      "Cost: 3.102616683744968\n",
      "Cost: 3.0518023829908185\n",
      "Cost: 2.9894974679332758\n",
      "Cost: 2.936367432101647\n",
      "Cost: 2.8670950472861474\n",
      "Cost: 2.8163083916965936\n",
      "Cost: 2.747282606925516\n",
      "Cost: 2.6878761485855964\n",
      "Cost: 2.6353355963326353\n",
      "Cost: 2.5822349821824364\n",
      "Cost: 2.5315025820638506\n",
      "Cost: 2.4778034324195906\n",
      "Cost: 2.430948685423539\n",
      "Cost: 2.3900591885855924\n",
      "Cost: 2.3385723267674132\n",
      "Cost: 2.2927213226567447\n",
      "Cost: 2.2565270598899434\n",
      "Cost: 2.2324626095342106\n",
      "Cost: 2.1931359511152335\n",
      "Cost: 2.1598311119057563\n",
      "Cost: 2.1246469540006077\n",
      "Cost: 2.0937683723800555\n",
      "Cost: 2.0612041909176106\n",
      "Cost: 2.036240921787178\n",
      "Cost: 2.0050053794156355\n",
      "Cost: 1.9816450489808528\n",
      "Cost: 1.9547285059769013\n",
      "Cost: 1.9328082947516088\n",
      "Cost: 1.9164832061350097\n",
      "Cost: 1.8991268550678149\n",
      "Cost: 1.8807506725381682\n",
      "Cost: 1.8574898357792766\n",
      "Cost: 1.828241219020384\n",
      "Cost: 1.812362690245684\n",
      "Cost: 1.7999506708780935\n",
      "Cost: 1.7834477443168306\n",
      "Cost: 1.7770262812338313\n",
      "Cost: 1.7673303852654483\n",
      "Cost: 1.7516325176765182\n",
      "Cost: 1.7380321350678205\n",
      "Cost: 1.7237325960164402\n",
      "Cost: 1.7191332783879862\n",
      "Cost: 1.725440434198259\n",
      "Cost: 1.718684001075729\n",
      "Cost: 1.7126323803642667\n",
      "Cost: 1.7024983881113027\n",
      "Cost: 1.6935848394946984\n",
      "Cost: 1.6850752602061654\n",
      "Cost: 1.677373619573758\n",
      "Cost: 1.671343221036209\n",
      "Cost: 1.6670403617081426\n",
      "Cost: 1.668650539376133\n",
      "Cost: 1.6643618716686235\n",
      "Cost: 1.6514013653049895\n",
      "Cost: 1.6450672440006389\n",
      "Cost: 1.6367907953445169\n",
      "Cost: 1.6314833657397747\n",
      "Cost: 1.6281097278346335\n",
      "Cost: 1.6252091619453057\n",
      "Cost: 1.622205469810923\n",
      "Cost: 1.6220580574393815\n",
      "Cost: 1.616321178427524\n",
      "Cost: 1.613437691668629\n",
      "Cost: 1.607795403249659\n",
      "Cost: 1.6027633366488663\n",
      "Cost: 1.6000577347911644\n",
      "Cost: 1.5979850820243606\n",
      "Cost: 1.5976059449097393\n",
      "Cost: 1.596410333486813\n",
      "Cost: 1.5923036581113197\n",
      "Cost: 1.5862773826567755\n",
      "Cost: 1.5859578917081587\n",
      "Cost: 1.586351748822781\n",
      "Cost: 1.5835828349492573\n",
      "Cost: 1.5820343647121078\n",
      "Cost: 1.5809929900480693\n",
      "Cost: 1.5806649634472825\n",
      "Cost: 1.5761174155026143\n",
      "Cost: 1.5737099117476712\n",
      "Cost: 1.5743620527358184\n",
      "Cost: 1.5756244155421384\n",
      "Cost: 1.5767259804038\n",
      "Cost: 1.5771369244749474\n",
      "Cost: 1.5774447423010327\n",
      "Cost: 1.5770392120638805\n",
      "Cost: 1.5757140812733623\n",
      "Cost: 1.5743889504828499\n",
      "Cost: 1.5730638196923385\n",
      "Cost: 1.5709222145935233\n",
      "Cost: 1.5663311865698077\n",
      "Cost: 1.5633731071626946\n",
      "Cost: 1.561761324909727\n",
      "Cost: 1.5591959185460946\n",
      "Cost: 1.5592436283879922\n",
      "Cost: 1.5587151399690207\n",
      "Cost: 1.557267050996691\n",
      "Cost: 1.5557849384670472\n",
      "Cost: 1.5504267068860151\n",
      "Cost: 1.5487383418662535\n",
      "Cost: 1.5478664511547926\n",
      "Cost: 1.546891434198272\n",
      "Cost: 1.5474916941587455\n",
      "Cost: 1.5463218557002474\n",
      "Cost: 1.5442324166883852\n",
      "Cost: 1.5443861481113117\n",
      "Cost: 1.5436202789808802\n",
      "Cost: 1.5434646316686247\n",
      "Cost: 1.5449419329729717\n",
      "Cost: 1.5463161080322623\n",
      "Cost: 1.5468738087832477\n",
      "Cost: 1.5457985609176328\n",
      "Cost: 1.5463902852259344\n",
      "Cost: 1.5476953575974788\n",
      "Cost: 1.546516983486805\n",
      "Cost: 1.5454417356211874\n",
      "Cost: 1.5457931838820569\n",
      "Cost: 1.5460415058978643\n",
      "Cost: 1.544782732814855\n",
      "Cost: 1.5427074854235552\n",
      "Cost: 1.5421620604037916\n",
      "Cost: 1.5424331096923303\n",
      "Cost: 1.5435206332891678\n",
      "Cost: 1.545218378704187\n",
      "Cost: 1.5468129978741505\n",
      "Cost: 1.5468777946725705\n",
      "Cost: 1.54541276909945\n",
      "Cost: 1.5454775658978703\n",
      "Cost: 1.5455423626962914\n",
      "Cost: 1.5448938114314699\n",
      "Cost: 1.546385304356368\n",
      "Cost: 1.5470603229729682\n",
      "Cost: 1.545595297399845\n",
      "Cost: 1.5448436198899653\n",
      "Cost: 1.5433785943168459\n",
      "Cost: 1.542730043052023\n",
      "Cost: 1.5427948398504443\n",
      "Cost: 1.5435729847121002\n",
      "Cost: 1.5436377815105211\n",
      "Cost: 1.54523240068049\n",
      "Cost: 1.5468270198504506\n",
      "Cost: 1.5460753423405706\n",
      "Cost: 1.5477730877555924\n",
      "Cost: 1.5471245364907702\n",
      "Cost: 1.549535629969033\n",
      "Cost: 1.5496004267674561\n",
      "Cost: 1.5504816978741738\n",
      "Cost: 1.5521794432891969\n",
      "Cost: 1.5515308920243756\n",
      "Cost: 1.551698815067854\n",
      "Cost: 1.551866738111333\n",
      "Cost: 1.552034661154811\n",
      "Cost: 1.5523057104433486\n",
      "Cost: 1.5525767597318851\n",
      "Cost: 1.552847809020424\n",
      "Cost: 1.5530157320639062\n",
      "Cost: 1.5523671807990826\n",
      "Cost: 1.5517186295342573\n",
      "Cost: 1.5540265967674578\n",
      "Cost: 1.552561571194341\n",
      "Cost: 1.5519130199295166\n",
      "Cost: 1.5527138920639048\n",
      "Cost: 1.5521911943168718\n",
      "Cost: 1.5523818446330775\n",
      "Cost: 1.551778747913705\n",
      "Cost: 1.5519921255026405\n",
      "Cost: 1.5522055030915756\n",
      "Cost: 1.5500725840006662\n",
      "Cost: 1.5479396649097596\n",
      "Cost: 1.5473592954631226\n",
      "Cost: 1.5483087483880213\n",
      "Cost: 1.549258201312922\n",
      "Cost: 1.5503107804828853\n",
      "Cost: 1.5505468853445443\n",
      "Cost: 1.550782990206209\n",
      "Cost: 1.5527087945145146\n",
      "Cost: 1.552391428388026\n",
      "Cost: 1.5519596397318995\n",
      "Cost: 1.55163097732083\n",
      "Cost: 1.5521187892180628\n",
      "Cost: 1.553423075423597\n",
      "Cost: 1.5547273616291288\n",
      "Cost: 1.5535822249097608\n",
      "Cost: 1.5524370881903962\n",
      "Cost: 1.551291951471025\n",
      "Cost: 1.5485138661350564\n",
      "Cost: 1.5472883304433545\n",
      "Cost: 1.5476957433682552\n",
      "Cost: 1.547286681984856\n",
      "Cost: 1.5460611462931602\n",
      "Cost: 1.5449387368465164\n",
      "Cost: 1.5431029793366349\n",
      "Cost: 1.5427970441982957\n",
      "Cost: 1.542491109059955\n",
      "Cost: 1.5421851739216148\n",
      "Cost: 1.5418792387832703\n",
      "Cost: 1.5423897779532338\n",
      "Cost: 1.5412673685065943\n",
      "Cost: 1.5401449590599525\n",
      "Cost: 1.5399421501666686\n",
      "Cost: 1.538922866965088\n",
      "Cost: 1.538616931826749\n",
      "Cost: 1.5391274709967087\n",
      "Cost: 1.540351358229905\n",
      "Cost: 1.5399082732891975\n",
      "Cost: 1.5387518402852418\n",
      "Cost: 1.5374922810362317\n",
      "Cost: 1.5362327217872167\n",
      "Cost: 1.5356865106014486\n",
      "Cost: 1.5351402994156773\n",
      "Cost: 1.5337776139216068\n",
      "Cost: 1.5339447507990756\n",
      "Cost: 1.5333985396133052\n",
      "Cost: 1.5344048780718036\n",
      "Cost: 1.5345947422219999\n",
      "Cost: 1.5347846063722024\n",
      "Cost: 1.53325991866469\n",
      "Cost: 1.531735230957182\n",
      "Cost: 1.5293571578741758\n",
      "Cost: 1.5269790847911735\n",
      "Cost: 1.5254174860164715\n",
      "Cost: 1.5276288800480926\n",
      "Cost: 1.5274939773998701\n",
      "Cost: 1.5281755490599558\n",
      "Cost: 1.5295704687832754\n",
      "Cost: 1.5294355661350525\n",
      "Cost: 1.530014011550073\n",
      "Cost: 1.5313058050283366\n",
      "Cost: 1.5327007247516604\n",
      "Cost: 1.5326689483484968\n",
      "Cost: 1.5326031483880214\n",
      "Cost: 1.5317208741192503\n",
      "Cost: 1.5308385998504712\n",
      "Cost: 1.5299563255816961\n",
      "Cost: 1.5290740513129208\n",
      "Cost: 1.5298587492180629\n",
      "Cost: 1.5299300990599622\n",
      "Cost: 1.5300014489018572\n",
      "Cost: 1.5300727987437586\n",
      "Cost: 1.5308234730915804\n",
      "Cost: 1.5299411988228055\n",
      "Cost: 1.5298753988623301\n",
      "Cost: 1.5289931245935575\n",
      "Cost: 1.528721072142964\n",
      "Cost: 1.5285521459374332\n",
      "Cost: 1.5299130421034395\n",
      "Cost: 1.530560590206207\n",
      "Cost: 1.530494790245729\n",
      "Cost: 1.5312454645935605\n",
      "Cost: 1.5297529685066047\n",
      "Cost: 1.5282604724196431\n",
      "Cost: 1.5266648500876288\n",
      "Cost: 1.5265990501271551\n",
      "Cost: 1.5279599462931637\n",
      "Cost: 1.5285043681508739\n",
      "Cost: 1.529762138071826\n",
      "Cost: 1.5303065599295367\n",
      "Cost: 1.530850981787241\n",
      "Cost: 1.5313613800876356\n",
      "Cost: 1.5310553040797295\n",
      "Cost: 1.5307492280718245\n",
      "Cost: 1.5297298040006797\n",
      "Cost: 1.5301370760560213\n",
      "Cost: 1.529831000048114\n",
      "Cost: 1.5303413983485075\n",
      "Cost: 1.5300353223406042\n",
      "Cost: 1.529729246332701\n",
      "Cost: 1.5294231703247976\n",
      "Cost: 1.529830442380133\n",
      "Cost: 1.5279945440006872\n",
      "Cost: 1.5290811405619515\n",
      "Cost: 1.5294543890599808\n",
      "Cost: 1.5298276375580009\n",
      "Cost: 1.5317307084275695\n",
      "Cost: 1.5343471273603795\n",
      "Cost: 1.5330874272418\n",
      "Cost: 1.5326442014315265\n",
      "Cost: 1.5343410198109695\n",
      "Cost: 1.5368543124987135\n",
      "Cost: 1.5371244347516788\n",
      "Cost: 1.5366812089414037\n",
      "Cost: 1.5362379831311286\n",
      "Cost: 1.5357947573208504\n",
      "Cost: 1.535351531510577\n",
      "Cost: 1.5349083057002997\n",
      "Cost: 1.5337517318267824\n",
      "Cost: 1.5325951579532646\n",
      "Cost: 1.532151932142987\n",
      "Cost: 1.5317087063327144\n",
      "Cost: 1.531402630324807\n",
      "Cost: 1.5310965543169022\n",
      "Cost: 1.5315038263722385\n",
      "Cost: 1.529667927992796\n",
      "Cost: 1.5306854218663084\n",
      "Cost: 1.5310926939216452\n",
      "Cost: 1.5314999659769852\n",
      "Cost: 1.5311938899690827\n",
      "Cost: 1.5308878139611757\n",
      "Cost: 1.5282354412734298\n",
      "Cost: 1.526399542893981\n",
      "Cost: 1.5284397635659188\n",
      "Cost: 1.530583110482917\n",
      "Cost: 1.5303801607200718\n",
      "Cost: 1.5309936852655268\n",
      "Cost: 1.5330339059374654\n",
      "Cost: 1.5328309561746198\n",
      "Cost: 1.5324908566093989\n",
      "Cost: 1.5336805794157264\n",
      "Cost: 1.5340538279137448\n",
      "Cost: 1.534323950166715\n",
      "Cost: 1.5337775981113762\n",
      "Cost: 1.5347610684275892\n",
      "Cost: 1.5349280644354966\n",
      "Cost: 1.5351981866884619\n",
      "Cost: 1.5347549608781845\n",
      "Cost: 1.5351282093762078\n",
      "Cost: 1.5347881098109943\n",
      "Cost: 1.5351613583090176\n",
      "Cost: 1.534004784435499\n",
      "Cost: 1.532848210561981\n",
      "Cost: 1.5309782886252237\n",
      "Cost: 1.531454663368303\n",
      "Cost: 1.531931038111385\n",
      "Cost: 1.5317280883485385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 1.53223848664894\n",
      "Cost: 1.5327716122220592\n",
      "Cost: 1.5333047377951847\n",
      "Cost: 1.5330213890600033\n",
      "Cost: 1.5327380403248274\n",
      "Cost: 1.531741343526409\n",
      "Cost: 1.5323775953445924\n",
      "Cost: 1.5313808985461732\n",
      "Cost: 1.5312006760560568\n",
      "Cost: 1.531020453565934\n",
      "Cost: 1.5316567053841184\n",
      "Cost: 1.5314764828939986\n",
      "Cost: 1.5321127347121801\n",
      "Cost: 1.5319325122220626\n",
      "Cost: 1.5317750170046698\n",
      "Cost: 1.5316175217872787\n",
      "Cost: 1.5306435522615844\n",
      "Cost: 1.5304860570441967\n",
      "Cost: 1.529512087518503\n",
      "Cost: 1.528538117992817\n",
      "Cost: 1.5275641484671227\n",
      "Cost: 1.5265901789414318\n",
      "Cost: 1.5280656323406419\n",
      "Cost: 1.5278277381509213\n",
      "Cost: 1.5307753422220662\n",
      "Cost: 1.5329064719849108\n",
      "Cost: 1.534324253684518\n",
      "Cost: 1.536455383447366\n",
      "Cost: 1.5378731651469715\n",
      "Cost: 1.538577598783336\n",
      "Cost: 1.5392820324196994\n",
      "Cost: 1.5391699917477617\n",
      "Cost: 1.540850776767526\n",
      "Cost: 1.5417150874789918\n",
      "Cost: 1.5416257740797767\n",
      "Cost: 1.543169409297167\n",
      "Cost: 1.5438161712339302\n",
      "Cost: 1.5451762812339271\n",
      "Cost: 1.5459261694157507\n",
      "Cost: 1.5458595832892668\n",
      "Cost: 1.5465063452260273\n",
      "Cost: 1.5464397590995445\n",
      "Cost: 1.5463731729730619\n",
      "Cost: 1.5477332829730654\n",
      "Cost: 1.5482769186647645\n",
      "Cost: 1.5481072062932253\n",
      "Cost: 1.5479374939216852\n",
      "Cost: 1.5461348329335454\n",
      "Cost: 1.545045520008644\n",
      "Cost: 1.5432768825778158\n",
      "Cost: 1.5430380675185271\n",
      "Cost: 1.5427992524592418\n",
      "Cost: 1.5440902597714934\n",
      "Cost: 1.5469110894552895\n",
      "Cost: 1.5497319191390795\n",
      "Cost: 1.5503095783880918\n",
      "Cost: 1.5516005857003459\n",
      "Cost: 1.552178244949359\n",
      "Cost: 1.5505127337635882\n",
      "Cost: 1.5503770449493592\n",
      "Cost: 1.550241356135132\n",
      "Cost: 1.5501056673209068\n",
      "Cost: 1.5485432823801972\n",
      "Cost: 1.5476942455027225\n",
      "Cost: 1.546006007044228\n",
      "Cost: 1.543604420522488\n",
      "Cost: 1.5420193083090472\n",
      "Cost: 1.540571345897981\n",
      "Cost: 1.5388490838821687\n",
      "Cost: 1.537862897202328\n",
      "Cost: 1.5368767105224896\n",
      "Cost: 1.5381336942774309\n",
      "Cost: 1.5377577294157727\n",
      "Cost: 1.5366684164908717\n",
      "Cost: 1.536395577874278\n",
      "Cost: 1.5369392135659765\n",
      "Cost: 1.5365632487043204\n",
      "Cost: 1.5353708095343594\n",
      "Cost: 1.535914445226059\n",
      "Cost: 1.5364580809177624\n",
      "Cost: 1.5370017166094654\n",
      "Cost: 1.5367288779928645\n",
      "Cost: 1.5364560393762643\n",
      "Cost: 1.5347565046331813\n",
      "Cost: 1.5354032665699444\n",
      "Cost: 1.536050028506699\n",
      "Cost: 1.536696790443464\n",
      "Cost: 1.5365270780719205\n",
      "Cost: 1.5348502706015656\n",
      "Cost: 1.5331961904039388\n",
      "Cost: 1.531542110206309\n",
      "Cost: 1.52988803000868\n",
      "Cost: 1.5298668984276516\n",
      "Cost: 1.5282128182300212\n",
      "Cost: 1.5305379833288402\n",
      "Cost: 1.52888390313121\n",
      "Cost: 1.5272298229335775\n",
      "Cost: 1.5272086913525555\n",
      "Cost: 1.5263710854632255\n",
      "Cost: 1.5263499538822007\n",
      "Cost: 1.5246958736845704\n",
      "Cost: 1.5262045644750852\n",
      "Cost: 1.5260803066489996\n",
      "Cost: 1.5259560488229125\n",
      "Cost: 1.5265451390600697\n",
      "Cost: 1.527134229297224\n",
      "Cost: 1.526906845226079\n",
      "Cost: 1.5273928092181754\n",
      "Cost: 1.527878773210272\n",
      "Cost: 1.526938041075888\n",
      "Cost: 1.5259973089414998\n",
      "Cost: 1.5250565768071112\n",
      "Cost: 1.5257487932893299\n",
      "Cost: 1.5256245354632432\n",
      "Cost: 1.525500277637153\n",
      "Cost: 1.5246626717478289\n",
      "Cost: 1.5260682362932851\n",
      "Cost: 1.5266573265304406\n",
      "Cost: 1.5272464167675994\n",
      "Cost: 1.5278355070047491\n",
      "Cost: 1.5284245972419108\n",
      "Cost: 1.5291168137241211\n",
      "Cost: 1.5306255045146326\n",
      "Cost: 1.5306271002063354\n",
      "Cost: 1.5314451702063387\n",
      "Cost: 1.5314467658980337\n",
      "Cost: 1.5306318872814373\n",
      "Cost: 1.5321633053446702\n",
      "Cost: 1.5327751228545567\n",
      "Cost: 1.5341343119849928\n",
      "Cost: 1.5370233234869708\n",
      "Cost: 1.539198986925702\n",
      "Cost: 1.5405581760561322\n",
      "Cost: 1.5417802153841946\n",
      "Cost: 1.5430022547122535\n",
      "Cost: 1.54422429404032\n",
      "Cost: 1.5447329853051412\n",
      "Cost: 1.5474848470047438\n",
      "Cost: 1.5487068863328057\n",
      "Cost: 1.549112451352565\n",
      "Cost: 1.5495180163723263\n",
      "Cost: 1.5499235813920889\n",
      "Cost: 1.5496157983486116\n",
      "Cost: 1.5478813191786542\n",
      "Cost: 1.546860188071934\n",
      "Cost: 1.547368879336759\n",
      "Cost: 1.5472673487834012\n",
      "Cost: 1.5464524701668019\n",
      "Cost: 1.5478807619849813\n",
      "Cost: 1.5470658833683808\n",
      "Cost: 1.5470674790600834\n",
      "Cost: 1.5477824228150225\n",
      "Cost: 1.5470706704434833\n",
      "Cost: 1.5470722661351812\n",
      "Cost: 1.5470738618268791\n",
      "Cost: 1.5463621094553426\n",
      "Cost: 1.5457534833288569\n",
      "Cost: 1.5459613315106757\n",
      "Cost: 1.5467453779533626\n",
      "Cost: 1.5468388036055358\n",
      "Cost: 1.5469322292577043\n",
      "Cost: 1.5470256549098749\n",
      "Cost: 1.5476952788229201\n",
      "Cost: 1.5483649027359616\n",
      "Cost: 1.5475047042774623\n",
      "Cost: 1.5473578538822044\n",
      "Cost: 1.5472337307596744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.3800e-04,  3.0619e-02, -6.4400e-04,  0.0000e+00,  0.0000e+00,\n",
       "        4.4000e-05, -1.1831e-02,  1.3000e-05, -2.0800e-04,  1.2420e-03,\n",
       "        2.5000e-04,  6.0909e-02, -3.4900e-04,  0.0000e+00])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
